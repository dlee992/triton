# TritonNvidiaGPUOps<!-- Autogenerated by mlir-tblgen; don't manually edit -->
### `triton_nvidia_gpu.cluster_arrive` (triton::nvidia_gpu::ClusterArriveOp)

Syntax:

```
operation ::= `triton_nvidia_gpu.cluster_arrive` attr-dict
```


Traits: `VerifyTensorLayoutsTrait`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>relaxed</code></td><td>::mlir::IntegerAttr</td><td>1-bit signless integer attribute</td></tr>
</table>

### `triton_nvidia_gpu.cluster_wait` (triton::nvidia_gpu::ClusterWaitOp)

Syntax:

```
operation ::= `triton_nvidia_gpu.cluster_wait` attr-dict
```


Traits: `VerifyTensorLayoutsTrait`

### `triton_nvidia_gpu.dot_async` (triton::nvidia_gpu::DotAsyncOp)

_Dot async_


Syntax:

```
operation ::= `triton_nvidia_gpu.dot_async` $a`,` $b`,` $c attr-dict `:` type($a) `*` type($b) `->` type($d)
```

$d = matrix_multiply($a, $b) + $c

Traits: `AlwaysSpeculatableImplTrait`, `VerifyTensorLayoutsTrait`

Interfaces: `ConditionallySpeculatable`, `InferTypeOpInterface`, `NoMemoryEffect (MemoryEffectOpInterface)`

Effects: `MemoryEffects::Effect{}`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>allowTF32</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr>
<tr><td><code>maxNumImpreciseAcc</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `a` | TensorOrMemDesc instance
| `b` | TensorOrMemDesc instance
| `c` | ranked tensor of floating-point or integer values

#### Results:

| Result | Description |
| :----: | ----------- |
| `d` | ranked tensor of floating-point or integer values

### `triton_nvidia_gpu.dot_wait` (triton::nvidia_gpu::DotWaitOp)

_Dot wait_


Syntax:

```
operation ::= `triton_nvidia_gpu.dot_wait` $inputs attr-dict `:` type($inputs)
```

Waits until there are $pendings or fewer outstanding async dot operations.

$inputs must be the tensors corresponding to the async dot ops that we're
waiting on.  For example, if there are N pending async dot ops and we call
`dot_wait 1`, then $inputs must be the result of the first dot op.

Traits: `VerifyTensorLayoutsTrait`

Interfaces: `InferTypeOpInterface`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>pendings</code></td><td>::mlir::IntegerAttr</td><td>32-bit signless integer attribute</td></tr>
</table>

#### Operands:

| Operand | Description |
| :-----: | ----------- |
| `inputs` | variadic of TensorOrMemDesc instance

#### Results:

| Result | Description |
| :----: | ----------- |
| `outputs` | variadic of TensorOrMemDesc instance

### `triton_nvidia_gpu.fence_async_shared` (triton::nvidia_gpu::FenceAsyncSharedOp)

_Fence proxy async_


Syntax:

```
operation ::= `triton_nvidia_gpu.fence_async_shared` attr-dict
```


Traits: `VerifyTensorLayoutsTrait`

#### Attributes:

<table>
<tr><th>Attribute</th><th>MLIR Type</th><th>Description</th></tr>
<tr><td><code>bCluster</code></td><td>::mlir::BoolAttr</td><td>bool attribute</td></tr>
</table>

### `triton_nvidia_gpu.get_cluster_cta_id` (triton::nvidia_gpu::GetClusterCTAIdOp)

Syntax:

```
operation ::= `triton_nvidia_gpu.get_cluster_cta_id` attr-dict `:` type($result)
```

Returns the one dimensional cluster_cta_id.

Traits: `AlwaysSpeculatableImplTrait`, `VerifyTensorLayoutsTrait`

Interfaces: `ConditionallySpeculatable`, `InferTypeOpInterface`, `NoMemoryEffect (MemoryEffectOpInterface)`

Effects: `MemoryEffects::Effect{}`

#### Results:

| Result | Description |
| :----: | ----------- |
| `result` | 32-bit signless integer

